{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "17df3e0c-6d1f-4560-ae89-af11fedb9ec3",
   "metadata": {},
   "outputs": [],
   "source": [
    "import datetime\n",
    "import json\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import numpy as np\n",
    "import urllib.request\n",
    "from torch.utils.data import Dataset, DataLoader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "011e59f4-71da-4651-b2ff-ad7b7482cb45",
   "metadata": {},
   "outputs": [],
   "source": [
    "# setup memory in the GPU 1\n",
    "#gpu_device = 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "caeb1d4b-6bf4-492d-86cd-3e64803f0122",
   "metadata": {},
   "outputs": [],
   "source": [
    "with urllib.request.urlopen(\n",
    "    \"https://saturn-public-data.s3.us-east-2.amazonaws.com/examples/pytorch/seattle_pet_licenses_cleaned.json\"\n",
    ") as f:\n",
    "    pet_names = json.loads(f.read().decode(\"utf-8\"))\n",
    "\n",
    "# Our list of characters, where * represents blank and + represents stop\n",
    "characters = list(\"*+abcdefghijklmnopqrstuvwxyz-. \")\n",
    "str_len = 8"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "4c4d252c-fc25-4487-b897-6d4aa8c773d5",
   "metadata": {},
   "outputs": [],
   "source": [
    "def format_training_data(pet_names, device=None):\n",
    "    def get_substrings(in_str):\n",
    "        # add the stop character to the end of the name, then generate all the partial names\n",
    "        in_str = in_str + \"+\"\n",
    "        res = [in_str[0:j] for j in range(1, len(in_str) + 1)]\n",
    "        return res\n",
    "\n",
    "    pet_names_expanded = [get_substrings(name) for name in pet_names]\n",
    "    pet_names_expanded = [item for sublist in pet_names_expanded for item in sublist]\n",
    "    pet_names_characters = [list(name) for name in pet_names_expanded]\n",
    "    pet_names_padded = [name[-(str_len + 1) :] for name in pet_names_characters]\n",
    "    pet_names_padded = [\n",
    "        list((str_len + 1 - len(characters)) * \"*\") + characters for characters in pet_names_padded\n",
    "    ]\n",
    "    pet_names_numeric = [[characters.index(char) for char in name] for name in pet_names_padded]\n",
    "\n",
    "    # the final x and y data to use for training the model. Note that the x data needs to be one-hot encoded\n",
    "    if device is None:\n",
    "        y = torch.tensor([name[1:] for name in pet_names_numeric])\n",
    "        x = torch.tensor([name[:-1] for name in pet_names_numeric])\n",
    "    else:\n",
    "        y = torch.tensor([name[1:] for name in pet_names_numeric], device=device)\n",
    "        x = torch.tensor([name[:-1] for name in pet_names_numeric], device=device)\n",
    "    x = torch.nn.functional.one_hot(x, num_classes=len(characters)).float()\n",
    "    return x, y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "ae07e201-74f0-47a0-a242-aed2df354d3f",
   "metadata": {},
   "outputs": [],
   "source": [
    "class OurDataset(Dataset):\n",
    "    def __init__(self, pet_names, device=None):\n",
    "        self.x, self.y = format_training_data(pet_names, device)\n",
    "        self.permute()\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        idx = self.permutation[idx]\n",
    "        return self.x[idx], self.y[idx]\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.x)\n",
    "\n",
    "    def permute(self):\n",
    "        self.permutation = torch.randperm(len(self.x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "95d61e47-6fe3-4631-b930-3cb3786e6e72",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Model(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(Model, self).__init__()\n",
    "        self.lstm_size = 128\n",
    "        self.lstm = nn.LSTM(\n",
    "            input_size=len(characters),\n",
    "            hidden_size=self.lstm_size,\n",
    "            num_layers=4,\n",
    "            batch_first=True,\n",
    "            dropout=0.1,\n",
    "        )\n",
    "        self.fc = nn.Linear(self.lstm_size, len(characters))\n",
    "\n",
    "    def forward(self, x):\n",
    "        output, state = self.lstm(x)\n",
    "        logits = self.fc(output)\n",
    "        return logits"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "8c0b0e13-c272-4290-8fd5-dc963841b6ba",
   "metadata": {},
   "outputs": [],
   "source": [
    "def train():\n",
    "    num_epochs = 8\n",
    "    batch_size = 4096\n",
    "    lr = 0.001\n",
    "    device = torch.device(0)\n",
    "\n",
    "    dataset = OurDataset(pet_names, device=device)\n",
    "    loader = DataLoader(dataset, batch_size=batch_size, shuffle=True, num_workers=0)\n",
    "\n",
    "    model = Model()\n",
    "    model = model.to(device)\n",
    "\n",
    "    criterion = nn.CrossEntropyLoss()\n",
    "    optimizer = optim.Adam(model.parameters(), lr=lr)\n",
    "\n",
    "    for epoch in range(num_epochs):\n",
    "        dataset.permute()\n",
    "        for i, (batch_x, batch_y) in enumerate(loader):\n",
    "            optimizer.zero_grad()\n",
    "            batch_y_pred = model(batch_x)\n",
    "\n",
    "            loss = criterion(batch_y_pred.transpose(1, 2), batch_y)\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "        #print(\n",
    "        #    f\"{datetime.datetime.now().isoformat()} - epoch {epoch} complete - loss {loss.item()}\"\n",
    "        #)\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4ab22781-2630-4277-8d62-e266641ece0b",
   "metadata": {},
   "outputs": [],
   "source": [
    "%timeit -n 5000 model = train()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "5cca9ad9-1157-42d5-8505-89c79e1fd64b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_name(model, characters, str_len):\n",
    "    device = torch.device(0)\n",
    "    in_progress_name = []\n",
    "    next_letter = \"\"\n",
    "    while not next_letter == \"+\" and len(in_progress_name) < 30:\n",
    "        # prep the data to run in the model again\n",
    "        in_progress_name_padded = in_progress_name[-str_len:]\n",
    "        in_progress_name_padded = (\n",
    "            list((str_len - len(in_progress_name_padded)) * \"*\") + in_progress_name_padded\n",
    "        )\n",
    "        in_progress_name_numeric = [characters.index(char) for char in in_progress_name_padded]\n",
    "        in_progress_name_tensor = torch.tensor(in_progress_name_numeric, device=device)\n",
    "        in_progress_name_tensor = torch.nn.functional.one_hot(\n",
    "            in_progress_name_tensor, num_classes=len(characters)\n",
    "        ).float()\n",
    "        in_progress_name_tensor = torch.unsqueeze(in_progress_name_tensor, 0)\n",
    "\n",
    "        # get the probabilities of each possible next character by running the model\n",
    "        with torch.no_grad():\n",
    "            next_letter_probabilities = model(in_progress_name_tensor)\n",
    "\n",
    "        next_letter_probabilities = next_letter_probabilities[0, -1, :]\n",
    "        next_letter_probabilities = (\n",
    "            torch.nn.functional.softmax(next_letter_probabilities, dim=0).detach().cpu().numpy()\n",
    "        )\n",
    "        next_letter_probabilities = next_letter_probabilities[1:]\n",
    "        next_letter_probabilities = [\n",
    "            p / sum(next_letter_probabilities) for p in next_letter_probabilities\n",
    "        ]\n",
    "\n",
    "        # determine what the actual letter is\n",
    "        next_letter = characters[\n",
    "            np.random.choice(len(characters) - 1, p=next_letter_probabilities) + 1\n",
    "        ]\n",
    "        if next_letter != \"+\":\n",
    "            # if the next character isn't stop add the latest generated character to the name and continue\n",
    "            in_progress_name.append(next_letter)\n",
    "    # turn the list of characters into a single string\n",
    "    pet_name = \"\".join(in_progress_name).title()\n",
    "    return pet_name"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "a0621490-ff24-4c5a-a2c8-ee424fa00aef",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['Mlyo', 'Stelsy', 'Telky', 'Mohli L Mepkeo', 'Sotpie', 'Sceoweis', 'Lakisa Sinybin', 'Bevi', 'Gumo', 'Sharlef', 'Fulbe', 'Roclee', 'Pibysha', 'Maeley', 'Vooil', 'Hoatya', 'Socan', 'Telo Bsalela', 'Dilos', 'Gannl', 'Baize', 'Chiviy', 'Begta', 'Macdlorlte', 'Ezcie', 'Feen', 'Cabiletg', 'Brikankran', 'Matsie', 'Maiopas', 'Meldee', 'Boto', 'Jufi', 'Mlova Jos', 'Tonva', 'Ruma', 'Oni', 'Tacgyslanri', 'Gabla', 'Neiga', 'Rarre', 'Asihea Deruly', 'Shoxo', 'Pepny', 'Dhoy', 'Geop', 'Gabbee', 'Sama', 'Yona', 'Geegka']\n"
     ]
    }
   ],
   "source": [
    "# Generate 50 names then filter out existing ones\n",
    "generated_names = [generate_name(model, characters, str_len) for i in range(0, 50)]\n",
    "generated_names = [name for name in generated_names if name not in pet_names]\n",
    "print(generated_names)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f76fb3c7-0b1c-4057-aeb2-b2365a2936a9",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "pytorch",
   "language": "python",
   "name": "saturn-pytorch"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
